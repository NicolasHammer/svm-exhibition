{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Support Vector Machine Exhibition"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In this notebook we will be looking at an implementation of the linear Support Vector Machine from scratch and compare it against its sklearn counterpart.  A linear Support Vector Machine is a line whose weights are trained by a gradient descent process that searches for a classifier with the best margins between groups of points.  To begin, let's import all the relevant packages that'll be used in the notebook."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "# Import relevant packages\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from sklearn.datasets import make_blobs\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.svm import LinearSVC\n",
                "\n",
                "import from_scratch.split_data as split_data\n",
                "import from_scratch.svm as svm\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 2D Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As a sanity check, let's generate some 2D blobs and see how both our from-scratch SVM and the sklearn SVM do in producing a maximum margin classifier."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# Create data\n",
                "TwoDFeatures, TwoDTargets = make_blobs(\n",
                "    n_samples=200, n_features=2, centers=2, cluster_std=1.5)\n",
                "\n",
                "ClassA = TwoDTargets == 0\n",
                "TwoDTargets[ClassA] = -1\n",
                "plt.scatter(TwoDFeatures[ClassA, 0], TwoDFeatures[ClassA, 1], color=\"red\")\n",
                "\n",
                "ClassB = TwoDTargets == 1\n",
                "plt.scatter(TwoDFeatures[ClassB, 0], TwoDFeatures[ClassB, 1], color=\"blue\")\n",
                "\n",
                "plt.plot()\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ],
                        "image/png": "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"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## From Scratch Implementation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "# Add bias to features\n",
                "TwoDFeatures_modded = np.hstack(\n",
                "    (TwoDFeatures, np.ones((TwoDFeatures.shape[0], 1))))\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "# Train/test split\n",
                "train_features, train_targets, test_features, test_targets = split_data.train_test_split(\n",
                "    TwoDFeatures_modded.T, TwoDTargets.reshape(1, TwoDTargets.shape[0]))\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "# Train model\n",
                "svm_model = svm.SVM(train_features.shape[0])\n",
                "svm_model.fit(train_features, train_targets)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "| epoch 1 | loss 12.51523697782912\n",
                        "| epoch 2 | loss 0.17337769614165974\n",
                        "| epoch 4 | loss 0.1732667698608621\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "# Test model\n",
                "predictions = svm_model.predict(test_features)\n",
                "print(\n",
                "    f\"Accuray = {np.sum(predictions == test_targets)/predictions.shape[1] * 100 :2.3f}%\")\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Accuray = 100.000%\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "# Visualize model\n",
                "line = svm_model.weights.T\n",
                "w_0 = line[2]\n",
                "w_1 = line[0]\n",
                "w_2 = line[1]\n",
                "\n",
                "discriminator = -(w_1/w_2)*test_features[0, :] - (w_0/w_2)\n",
                "\n",
                "test_ClassA = test_targets[0, :] == -1\n",
                "plt.scatter(test_features[0, test_ClassA],\n",
                "            test_features[1, test_ClassA], color=\"red\")\n",
                "\n",
                "test_ClassB = test_targets[0, :] == 1\n",
                "plt.scatter(test_features[0, test_ClassB],\n",
                "            test_features[1, test_ClassB], color=\"blue\")\n",
                "\n",
                "plt.plot(test_features[0, :], discriminator, color=\"black\")\n",
                "plt.plot()\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 12
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ],
                        "image/png": "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"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Sklearn Implementation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "# Train-test split\n",
                "train_features, test_features, train_targets, test_targets = train_test_split(\n",
                "    TwoDFeatures, TwoDTargets)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "# Train model\n",
                "linear_svm = LinearSVC(loss=\"hinge\", max_iter=5000)\n",
                "linear_svm.fit(train_features, train_targets)\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "LinearSVC(loss='hinge', max_iter=5000)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 14
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "# Test model\n",
                "predictions = linear_svm.predict(test_features)\n",
                "print(\n",
                "    f\"Accuray = {np.sum(predictions == test_targets)/predictions.shape[0] * 100 :2.3f}%\")\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Accuray = 100.000%\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "# Visualize model\n",
                "w_1 = linear_svm.coef_[0, 0]\n",
                "w_2 = linear_svm.coef_[0, 1]\n",
                "w_0 = linear_svm.intercept_[0]\n",
                "\n",
                "discriminator = -(w_1/w_2)*test_features[:, 0] - (w_0/w_2)\n",
                "\n",
                "test_ClassA = test_targets == -1\n",
                "plt.scatter(test_features[test_ClassA, 0],\n",
                "            test_features[test_ClassA, 1], color=\"red\")\n",
                "\n",
                "test_ClassB = test_targets == 1\n",
                "plt.scatter(test_features[test_ClassB, 0],\n",
                "            test_features[test_ClassB, 1], color=\"blue\")\n",
                "\n",
                "plt.plot(test_features[:, 0], discriminator, color=\"black\")\n",
                "plt.plot()\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 16
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ],
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdiElEQVR4nO3dfZBV9XkH8O93QZGlWnXZooDsonVCMKWxLtGGSX1BDL4kdsaQkCwiErOpY1vsJCbaTdNkMlsb0rE1SVOzw0so3NEo6iST4AuYOIkTJF2MDQZQ0bDIirIYLCIgL/fpH+de2Hv3nPt2zr3n7fuZubN7z7l7zrML+9xnn9/v/A7NDCIiEn9NYQcgIiLBUEIXEUkIJXQRkYRQQhcRSQgldBGRhFBCFxFJiIoTOsllJHeTfGHItm+R3ErytyQfJXl6XaIUEZGyqqnQfwBgdtG2tQA+YGbTALwE4K6A4hIRkSpVnNDN7BcA/lC07UkzO5p7+iyAiQHGJiIiVRgZ4LEWAvhhJS8cO3astbe3B3hqEZHk27hx4x4za/XaH0hCJ9kN4CiATInXdAHoAoBJkyahr68viFOLiKQGyf5S+33PciG5AMB1ADqtxMIwZtZrZh1m1tHa6vkGIyIiNfJVoZOcDeBLAC41swPBhCQiIrWoZtri/QDWA3gfyZ0kPwvguwBOBbCW5PMk76tTnCIiUkbFFbqZfdpl89IAYxERER90paiISEIooUt8ZTJAezvQ1OR8zHhOshJJhSDnoYs0TiYDdHUBB3Jj8f39znMA6OwMLy6REKlCl3jq7j6RzPMOHHC2i6SUErrE044d1W0XSQEldImnSZOq2y6SAkroEk89PUBzc+G25mZnu0hKKaFLPHV2Ar29QFsbQDofe3s1ICqpplkuEl+dnUrgIkOoQhcRSQgldBGRhFBCFxFJCCV0EZGEUEIXEUkIJXQRkYRQQhcRSYhq7li0jORuki8M2XYmybUkX859PKM+YYqISDnVVOg/ADC7aNudAJ4ys/MBPJV7LiIiIag4oZvZLwD8oWjz9QBW5D5fAeCvgwlLRESq5beHPs7MduU+fwPAOJ/HExGRGgU2KGpmBsC89pPsItlHsm9wcDCo04qISI7fhP4mybMBIPdxt9cLzazXzDrMrKO1tdXnaUVEpJjfhP5jADflPr8JwI98Hk+iTjdmFomsaqYt3g9gPYD3kdxJ8rMA/hXALJIvA7gy91z8imrSzGSAhQudGzKbOR8XLoxOfCIpR6f13VgdHR3W19fX8PPGQvHd7AHnTjxRuHnD2LHAW28N397SAuzZ0/h4RFKG5EYz6/DarytFoybKd7N3S+altotIQymhR43uZi8iNVJCj5oo382+paW67SLSUEroUVOPu9kHNch6773ASScVbjvpJGe7iIROCT1qgr6bfX6QdejMlK6u2pJ6ZyewfHlhbMuXhz9YKyIANMvlhEzGGXjcscNpb/T0JCNRtbc7SbxYWxuwfXujoxERHzTLpRJBVrFRo0HW4aI6z1/Ep3gn9KB+MaM8VdCvKA+yhiHJb96SevFN6EH+Yia5ig1ykDUJlW2S37wl9eKb0IP8xUxKFeuWcIMaZE1KZZvkN28RM2v446KLLrKqrVpl1tZmRjofnbQy/EHWduzm5sLjNDc72+Oi3t+D18+8rS2Y4zdKUr4PSSUAfVYit8ajQnerDkn319ZSVQc9VbDRMhngppvq20pISmVbj3n+IhERj4Tu1l4xG57U/fxidnY60/iyWedjFJO5W0sl/2Z37Jj711SacMv1x5PSlor7m7dIKaXK93o9qm65kN4tlqFtmDi1SKrl1VJpafH+2VTaSqikXZOEtpRISLLZrC1evNhuuOEGe/fdd2s+Dsq0XOKR0NX3LD1u4PWoNOFW+vMtHsdQMhcpaXBw0C6++OL87TkNgO3cubPm45VL6PFouajvWX2vesSIylsJlfbH49CWEomAJ554AiTR2tqKDRs2AACmT5+O3bt3Y8KECXU7byAJneQ/kPwdyRdI3k/ylCCOe5z6nt696pYW9ze7FSsq//lEsT+ehDnvkipHjhzBbbfdBpKYPXv28e133303stksfv3rX6Pu91MuVb5X8gAwAcDvAYzOPX8QwIJSX1PTtMW0K9XD9tsKiVp/PGrxiJTw8ssv27hx4wraKk1NTbZx48bAz4V699BzCf01AGcCGAngJwCuKvU1Sug1qmcPO0r9cY2ZSAwsWbKkIIkDsE984hO+Bj3LKZfQA1ltkeQiAD0ADgJ40sxK/q0fydUWJTqampwUXox0+vciIXnnnXcwd+5crFmzpmB7JpPBZz7zmbqfv+6rLZI8A8D1ACYDGA9gDMl5Lq/rItlHsm9wcNDvaSXJotjTl1Rbv349SOK00047nszPPfdcbN++HWbWkGReiSAGRa8E8HszGzSzIwAeAfDh4heZWa+ZdZhZR90HBiTeNKtJIiCbzeKrX/0qSOLDHz6R0r74xS/i6NGjeOWVV9DW1hZihMONDOAYOwBcQrIZTstlJgD1U6R2+dk5SbzhiETe66+/jlmzZmHz5s0F23/+85/jsssuCyeoCvmu0M1sA4DVAJ4DsCl3zF6/x42FKE6ti2JMtdCcd2mwRx55BCQxYcKE48n88ssvx969e2FmkU/mAGJypWgURXFqXdAxRWnmi0gdHDp0yG688cZhs1W+853vhB2aKzRilku1EjHLJYr36gwypvyiX0MXRWtuTt8FXZJIP/zhDzF37tyCbaeddhrWr1+PqVOnhhRVeeVmuSih1yqKU+uCjCmKb1giPpgZJk+ejP6i/9ef+tSnsGLFCowaNSqkyCqnm0TXSxSn1gUZU1LWP5fU6+vrA0k0NTUVJPMFCxbAzPDAAw/EIplXQgm9VlGcWhdkTFF8wxKpwowZM0AS06dPL9j+3HPPwcywfPnykCKrHyX0WkVxwbAgY4riG5ZIGQcPHgRJkMSvfvWrgn1Hjx6FmeHCCy8MKbr6U0L3I4pT64KKKYpvWCIeli9fDpJoLipC5s2bd3wGyIgRI0KKrnGCuLBIkqqzUwlcIo0e9xbetm0bzjvvvAZHEz4ldBGJle3bt2Py5Mmu+8KYtRclarmISCzccsstIDksmX//+98fupx3qqlCF5HIymaznr3v/fv3Y8yYMQ2OKNpUoddTUtZVEWmwdevWgeSwZP7BD37weDWuZD6cKvR6Kb50vr/feQ5ooFHEw4QJE/D6668P275+/XpccsklIUQUL6rQ66W7u3AdFMB53t1duE1VvKTc7t27j88dL07m2WwWZqZkXiEl9KGCTK6VXDqfr+L7+501WPJVvJK6pMCCBQtAEuPGjSvYfscdd5xYPdBjWqK40+JceUGvLljJ4lZaAEtSyCtJ79q1C2eddVaDo4kXLc5VqUpbJJWq5NJ5LYAlKbFmzZrjbZVi+Wpcydy/QBI6ydNJria5leQWkn8ZxHEbKujkWsml81oASxIun8Svvfbagu1D2yoSnKBmudwL4HEz+wTJkwE0l/uCyJk0yb394Se5lrt0vqfHvc2jBbAkxg4cOOA5pfDAgQMYPXp0gyNKD98VOsk/BvBXAJYCgJkdNrO3/R634cJYXVALYEmC3HDDDSDpmszz1biSeX0FUaFPBjAIYDnJPwewEcAiM3s3gGM3Tlh3mtcCWBJzXoOcTzzxBK666qoGR5Nuvme5kOwA8CyAGWa2geS9APaZ2T8Vva4LQBcATJo06aLi20CJSHw888wz+MhHPuK6T33x+mnELJedAHaa2Ybc89UA/qL4RWbWa2YdZtbR2toawGmlIrpwSQKUH+QsTubjx4/XIGcE+E7oZvYGgNdIvi+3aSaAzX6PKwHQhUsSgGPHjnlOOXzllVdgZhgYGAghMikW1Dz0vwOQIflbAB8E8C8BHVf8CHpuvaTK3LlzQRIjRw4fastX4+eee24IkYmXQKYtmtnzADz7OhISXbgkNfAa5Jw9ezYee+yxBkcj1dBqi0lWj7n1kkgvvvgipkyZ4rrvyJEjrlW6RI8u/Y86P4OaYcytl1jJ98bdknm+raJkHh9K6FHmd1BTFy6JB69BzpUrV2q2SoxptcUo02qMEqBvfvObuPPOO133KYHHQ7l56PpbKso0qCkBKLWmuBJ5sqjlEmVajVFqtH//fs+2yq5du9RWSSgl9CjToKZUacyYMSCJU089ddg+rTuefEroUaZBTalQvho/UHQhWVdXl6rxFFEPPeq0GqN4WLlyJebPn++6L5vN6n6cKaSELhIzGuQUL2q5iMSAmXkOcj766KNqqwgAVegikTZu3Djs3r3bdZ8SuBRTQheJILVVpBZquYhExNatWz3bKvv27VNbRcpShS4SMlXjEhRV6CIh8arGb775ZlXjUpPAEjrJESR/Q/InQR1TJGnuvvtuz0SeT+LLli0LITJJgiBbLosAbAFwWoDHFEkEtVWkEQKp0ElOBHAtgCVBHE8kCQ4dOuRZjW/evFltFQlcUBX6fwD4EoDhKwKJpIyqcQmL7wqd5HUAdpvZxjKv6yLZR7JvcHDQ72lFIserGp8yZYqqcWmIIFouMwB8nOR2AA8AuILkquIXmVmvmXWYWUdra2sApxUJ3y9/+UvPRH7s2DGYGbZs2RJCZJJGvlsuZnYXgLsAgORlAL5oZvP8HlckytRWkSjSPHSRKnhV46tWrVJbRUIX6JWiZvY0gKeDPKZI2D75yU/ioYcect2nBC5Rokv/RTyorSJxo5aLyBBvvvmmZ1tlz549aqtIpKlCF4GqcUkGVeiSal7V+Pz581WNS+wooUvqfO973yu7QNaKFStCiEzEH7VcJDXUVpGkU4UuiXbs2DHPavypp55SW0USRRW6JNLo0aNx6NAh131K4JJUSuiSKGqrSJqp5SKxt3HjRs+2ynvvvae2iqSGKnSJLVXjIoVUoUvseFXjPT09qsYl1VShSyzcfvvtuPfee133KYGLOJTQJdLUVhGpnFouEjn79+/3bKv09/errSLiwXeFTvIcAP8NYBwAA9BrZu5/G4uUoGpcxJ8gKvSjAL5gZlMBXALgNpJTAziupIRXNT5nzhxV4yJVCOKeorsA7Mp9/g7JLQAmANjs99iSXI8//jiuvvpq133ZbLZktS4i7gIdFCXZDuBCABuCPK4kh9oqIvUT2KAoyT8C8DCA281sn8v+LpJ9JPsGBweDOq3EgJl5tlXWrVuntopIQAJJ6CRPgpPMM2b2iNtrzKzXzDrMrKO1tTWI00rEfexjHwNJNDUN/2+WT+IzZ84MITKRxstkgPZ2oKnJ+ZjJBH+OIGa5EMBSAFvM7B7/IUncqa0iUiiTAbq6gAMHnOf9/c5zAOjsDO48QVToMwDcCOAKks/nHtcEcFyJkf7+fs+2yv79+9VWSZhGVJtJ0t19IpnnHTjgbA9SELNcngGgKQkppWo8fRpVbSbJjh3Vba+VrhSVmnhV49/4xjdUjSdckNVmWir9SZOq214rJXSp2NKlS8veXPkrX/lKCJFJIwVVbeYr/f5+wOxEpZ/EpN7TAzQ3F25rbna2B0kJXcrKJ/Fbbrll2D5V4+kTVLXZqL5yFHR2Ar29QFsbQDofe3uDb1EpoYurw4cPe1bj27ZtUyJPsaCqzUb1laOisxPYvh3IZp2P9RhvUEKXApdffjlIYtSoUcP25ZP4eeedF0Jk4iasHvTo0Sc+b2mprdpsVF85TZTQBcCJtsrTTz9dsH3+/PmqxiMqjB50/pxvvXVi28GD1R+jvd2Jt/gPwHr0ldOEYfyidnR0WF9fX8PPK4U2bdqEadOmue47duyY6xWeEh35pFisrc35kz6K5yye8gg4Sd3MOUZPj6Y+lkJyo5l1eO3XHYtSSHPHkyGMHrTfc7oNhOaTeb3ehNJEJViKeA1yrl27Vm2VGAqjB+33nGkbCG00JfSE+/a3v1127viVV14ZQmTiV6PmNgd5Tg2E1pcSekLlk/iiRYsKtre0tKgaT4hGzW0O8pxhvAmliQZFE+Ttt9/GGWec4bpv3759OPXUUxsckchwmYzTS9+xw6nMNRBaOQ2KpsDEiRMxMDDguk+VuERNZ6cSeL2o5RJj+bZKcTK/55571FYRSSFV6DGzbt06zJo1y3WfErhIuqlCj4l8Ne6WzFWNSyYDjB3rDFSSzudJXLVQSgvqnqKzSb5IchvJO4M4pgDZbNZzyuGWLVuUyAWAk7hvvrnwcvy33gIWLqwsqadlTfI08J3QSY4A8J8ArgYwFcCnSU71e9w0W7x4MUhixIgRw/blk/iUKVNCiEyiqLsbOHJk+PbDh8svRZumNcnTIIgK/UMAtpnZq2Z2GMADAK4P4Lipk6/Gv/zlLxds//znP69qXDyVusqy3BWYaVqTPA2CGBSdAOC1Ic93Arg4gOOmwhtvvIGzzz7bdd+RI0cwcqTGraW0SZPcF8zK7ytFl+InS8MGRUl2kewj2Tc4ONio00bWBRdcAJKuyTxfjSuZSyV6eoCTThq+/eSTy1+BqUvxkyWIhD4A4JwhzyfmthUws14z6zCzjtbW1gBOG0/5tsrmzZsLtj/zzDNqq0hNOjuB5cudG03ktbQAy5aVv4BHl+InSxAJ/X8AnE9yMsmTAcwF8OMAjpsYP/3pT8sukDVjxowQIpOk6OwE9uxxBjbNnM8ruRozjPVgpH58J3QzOwrgbwE8AWALgAfN7Hd+j5sE+SR+3XXXFWyfNWuWqvGISfPUvUbc61IaI5AmrZmtAbAmiGPF3eHDh13vxwkAe/fuxemnn97YgKSs4rvo5KfuAUpuEi+6UjQgX//618veXFnJPJo0dU+SQgndp3xb5Wtf+1rB9ocfflhtlZjwmvKnqXvJldQWm+bF1WBgYAATJ0503Ze/XF/iIZM5cZPiYpq6l0xJbrGpQq/CnDlzQHJYMr/ggguOV+NK5vHS3e2ezElN3UuK4mp80aLkttiU0MvIJ2mSWL16dcG+gYEBmBleeOGFkKITv7zaKmbRr9aS2jYIkttaNUMXMRsqCS02JXQP69atA0k0NQ3/EeWr8fHjx4cQmQTJq63S1taY89ealKO4qFYU32DcBry9JKLFlk9OjXxcdNFFFlUXX3yxARj2WLp0adihSR2sWmXW3Jy/HMd5NDc726N87ra2wq/LP9ra6htvW5sZ6XwcGmeYP8dSSPefU/EjCrFWAkCflcitSuhm9t5777kmcQB25MiRsMOTOiuVqOrJT1L2SlRkfWItl7DDeIOphFdcLS3h/Jv7pYRews9+9jPXJD5v3rywQ5MU8JOUG51Ay52v0W8wlYrqXw61KpfQU9lD/+hHPwqSuOKKKwq279q1C2aGlStXhhSZpImflQ4bvahWuWV2o7pqY9rWqklNQh8cHDw+W+XJJ588vv3SSy89/u521llnhRihpM011zhJZqhKk3KjE1W5hB3lVRtTtVZNqfK9Xo9Gtlzuu+8+17bK2rVrGxaDNEZYvfBauLUCSLNbbw07MneVtC7i9POPK5RpudB5TWN1dHRYX19f3Y6fzWYxZswYHDp0aNi+Q4cOeS6eJfFVfPUf4FSIUf3zur3dfcmBtjanioyiTMaZBrhjh1OZ9/RE82ebZCQ3mlmH5/4kJfRNmzZh2rRpw7bfcccdWLx4ceDnk+iIW4JsavK+QjWbbXw8Eg/lEnoieui33norSA5L5i+99BLMTMk8BeJ2b8yoDiKWEsULh6RQbBP64cOH8bnPfQ4kcd999x3fPn78eGSzWZgZzj///BAjlEaKW4KM8iCimyhemSrD+UroJL9FcivJ35J8lOTpAcXlaevWrTjzzDMxatQoLFmy5Pj2lStXwswwMDCgBbJSKG4JMm7T6bRmfDz4rdDXAviAmU0D8BKAu/yH5O2hhx7C+9//fuzduxcA0NnZiYMHD8LMMG/evHqeWiIubgkSiNd0uri1tNLKV0I3syfNuacoADwLwH2R8IC0t7dj8uTJePDBB2FmWLVqFU455ZR6nlJiJE4JMm7i1tJKqyB76AsBPBbg8YaZPn06Xn31VcyZM6eepxFJnXIDnnFraaVV2TsWkVwHwO0Sym4z+1HuNd0AjgLwHCIh2QWgCwAm6W1dJDIquYNP/qPmoUeb73noJBcA+DyAmWZW0crD9b6wSEQqF7c5/GlWbh66r3uKkpwN4EsALq00mYtItGjAMzn89tC/C+BUAGtJPk/yvnJfICKNV6pHrgHP5PBVoZvZnwYViIjUR7keeU+P+zo4GvCMn9heKSoilSl3UVAc5/CLu0QtziUiw2khsORIxeJcIuJNPfL0UEIXiZhKVzWs9HW6KCg9fA2KikiwKrnIp5rXDX2ui4KSTz10kQip9CIfXQyUTuqhi8RIpRf56GIgcaOELhIhlQ5gaqBT3Cihi0TINdc40wmHchvA1ECnuFFCF4mITAZYsaJwzjgJ3HST+0CnLgaSYkrokmhxurGx2xWdZsCaNe6v1w09pJimLUpiVTO1Lwo00Cl+qUKXxIrbjY010Cl+KaFLYsWt4tVAp/ilhC6JFbeKVwOd4pcSuiRWHCteDXSKH4EkdJJfIGkkxwZxPJEgqOKVtPE9y4XkOQCuAhDRzqSkWWenErikRxAV+r/DuVF041f5EhGR43wldJLXAxgws/8NKB4REalR2ZYLyXUAznLZ1Q3gH+G0W8oi2QWgCwAmRXWagYhIjNW8HjrJPwPwFID8pRsTAbwO4ENm9kapr9V66CIi1Su3HnrNg6JmtgnAnww50XYAHWa2p9ZjiohI7TQPXUQkIQJbnMvM2oM6loiIVE8VukhI4rS0r8SDls8VCUHclvaVeFCFLhKCuC3tK/GghC4Sgrgt7SvxoIQuEoK4Le0r8aCELhKCOC7tK9GnhC4SAi3tK/WgWS4iIdHSvhI0VegiIgmhhC4ikhBK6CIiCaGELiKSEEroIiIJUfMNLnydlBwE0F/HU4wFkJR12fW9RJO+l2hK+vfSZmatXl8QSkKvN5J9pe7qESf6XqJJ30s0pf17UctFRCQhlNBFRBIiqQm9N+wAAqTvJZr0vURTqr+XRPbQRUTSKKkVuohI6iQyoZP8FsmtJH9L8lGSp4cdU7VIzib5IsltJO8MO55akTyH5M9Jbib5O5KLwo7JL5IjSP6G5E/CjsUvkqeTXJ37fdlC8i/DjqlWJP8h93/sBZL3kzwl7JgqRXIZyd0kXxiy7UySa0m+nPt4RrnjJDKhA1gL4ANmNg3ASwDuCjmeqpAcAeA/AVwNYCqAT5OcGm5UNTsK4AtmNhXAJQBui/H3krcIwJawgwjIvQAeN7MpAP4cMf2+SE4A8PcAOszsAwBGAJgbblRV+QGA2UXb7gTwlJmdD+Cp3POSEpnQzexJMzuae/osgIlhxlODDwHYZmavmtlhAA8AuD7kmGpiZrvM7Lnc5+/ASRgTwo2qdiQnArgWwJKwY/GL5B8D+CsASwHAzA6b2duhBuXPSACjSY4E0Azg9ZDjqZiZ/QLAH4o2Xw9gRe7zFQD+utxxEpnQiywE8FjYQVRpAoDXhjzfiRgnwTyS7QAuBLAh5FD8+A8AXwKQDTmOIEwGMAhgea6FtITkmLCDqoWZDQD4NwA7AOwC8H9m9mS4Ufk2zsx25T5/A8C4cl8Q24ROcl2uV1b8uH7Ia7rh/MmfCS9SAQCSfwTgYQC3m9m+sOOpBcnrAOw2s41hxxKQkQD+AsB/mdmFAN5FBX/WR1Guv3w9nDep8QDGkJwXblTBMWc6YtkpibG9Y5GZXVlqP8kFAK4DMNPiNzdzAMA5Q55PzG2LJZInwUnmGTN7JOx4fJgB4OMkrwFwCoDTSK4ys7gmjp0AdppZ/i+m1YhpQgdwJYDfm9kgAJB8BMCHAawKNSp/3iR5tpntInk2gN3lviC2FXopJGfD+bP442Z2IOx4avA/AM4nOZnkyXAGd34cckw1IUk4PdotZnZP2PH4YWZ3mdlEM2uH82/ysxgnc5jZGwBeI/m+3KaZADaHGJIfOwBcQrI5939uJmI6wDvEjwHclPv8JgA/KvcFsa3Qy/gugFEA1jr/tnjWzP4m3JAqZ2ZHSf4tgCfgjNYvM7PfhRxWrWYAuBHAJpLP57b9o5mtCS8kGeLvAGRyhcOrAG4OOZ6amNkGkqsBPAenzfobxOiqUZL3A7gMwFiSOwH8M4B/BfAgyc/CWZ32k2WPE79uhIiIuElky0VEJI2U0EVEEkIJXUQkIZTQRUQSQgldRCQhlNBFRBJCCV1EJCGU0EVEEuL/AS5PTEq+Ov8vAAAAAElFTkSuQmCC"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As we can see, both the from-scratch and sklearn implementations work perfectly at separating linearly separable blobs of data in 2D.  However, we could have simply used a perceptron here, so why is an SVM so useful?  Well, the SVM is very useful a separating data with many dimensions, as we will see in the following breast cancer data example."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Breast Cancer Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "To illustrate the efficacy of the from-scratch SVM in a high dimensional setting, we examine the the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) posted by the University of California Irvine.\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "# Load data\n",
                "original_data = pd.read_csv(\"data/breast_cancer.csv\", sep=',')\n",
                "original_data.head()\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
                            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
                            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
                            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
                            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
                            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
                            "\n",
                            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
                            "0          0.11840           0.27760          0.3001              0.14710   \n",
                            "1          0.08474           0.07864          0.0869              0.07017   \n",
                            "2          0.10960           0.15990          0.1974              0.12790   \n",
                            "3          0.14250           0.28390          0.2414              0.10520   \n",
                            "4          0.10030           0.13280          0.1980              0.10430   \n",
                            "\n",
                            "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
                            "0  ...          17.33           184.60      2019.0            0.1622   \n",
                            "1  ...          23.41           158.80      1956.0            0.1238   \n",
                            "2  ...          25.53           152.50      1709.0            0.1444   \n",
                            "3  ...          26.50            98.87       567.7            0.2098   \n",
                            "4  ...          16.67           152.20      1575.0            0.1374   \n",
                            "\n",
                            "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
                            "0             0.6656           0.7119                0.2654          0.4601   \n",
                            "1             0.1866           0.2416                0.1860          0.2750   \n",
                            "2             0.4245           0.4504                0.2430          0.3613   \n",
                            "3             0.8663           0.6869                0.2575          0.6638   \n",
                            "4             0.2050           0.4000                0.1625          0.2364   \n",
                            "\n",
                            "   fractal_dimension_worst  Unnamed: 32  \n",
                            "0                  0.11890          NaN  \n",
                            "1                  0.08902          NaN  \n",
                            "2                  0.08758          NaN  \n",
                            "3                  0.17300          NaN  \n",
                            "4                  0.07678          NaN  \n",
                            "\n",
                            "[5 rows x 33 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>diagnosis</th>\n",
                            "      <th>radius_mean</th>\n",
                            "      <th>texture_mean</th>\n",
                            "      <th>perimeter_mean</th>\n",
                            "      <th>area_mean</th>\n",
                            "      <th>smoothness_mean</th>\n",
                            "      <th>compactness_mean</th>\n",
                            "      <th>concavity_mean</th>\n",
                            "      <th>concave points_mean</th>\n",
                            "      <th>...</th>\n",
                            "      <th>texture_worst</th>\n",
                            "      <th>perimeter_worst</th>\n",
                            "      <th>area_worst</th>\n",
                            "      <th>smoothness_worst</th>\n",
                            "      <th>compactness_worst</th>\n",
                            "      <th>concavity_worst</th>\n",
                            "      <th>concave points_worst</th>\n",
                            "      <th>symmetry_worst</th>\n",
                            "      <th>fractal_dimension_worst</th>\n",
                            "      <th>Unnamed: 32</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>842302</td>\n",
                            "      <td>M</td>\n",
                            "      <td>17.99</td>\n",
                            "      <td>10.38</td>\n",
                            "      <td>122.80</td>\n",
                            "      <td>1001.0</td>\n",
                            "      <td>0.11840</td>\n",
                            "      <td>0.27760</td>\n",
                            "      <td>0.3001</td>\n",
                            "      <td>0.14710</td>\n",
                            "      <td>...</td>\n",
                            "      <td>17.33</td>\n",
                            "      <td>184.60</td>\n",
                            "      <td>2019.0</td>\n",
                            "      <td>0.1622</td>\n",
                            "      <td>0.6656</td>\n",
                            "      <td>0.7119</td>\n",
                            "      <td>0.2654</td>\n",
                            "      <td>0.4601</td>\n",
                            "      <td>0.11890</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>842517</td>\n",
                            "      <td>M</td>\n",
                            "      <td>20.57</td>\n",
                            "      <td>17.77</td>\n",
                            "      <td>132.90</td>\n",
                            "      <td>1326.0</td>\n",
                            "      <td>0.08474</td>\n",
                            "      <td>0.07864</td>\n",
                            "      <td>0.0869</td>\n",
                            "      <td>0.07017</td>\n",
                            "      <td>...</td>\n",
                            "      <td>23.41</td>\n",
                            "      <td>158.80</td>\n",
                            "      <td>1956.0</td>\n",
                            "      <td>0.1238</td>\n",
                            "      <td>0.1866</td>\n",
                            "      <td>0.2416</td>\n",
                            "      <td>0.1860</td>\n",
                            "      <td>0.2750</td>\n",
                            "      <td>0.08902</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>84300903</td>\n",
                            "      <td>M</td>\n",
                            "      <td>19.69</td>\n",
                            "      <td>21.25</td>\n",
                            "      <td>130.00</td>\n",
                            "      <td>1203.0</td>\n",
                            "      <td>0.10960</td>\n",
                            "      <td>0.15990</td>\n",
                            "      <td>0.1974</td>\n",
                            "      <td>0.12790</td>\n",
                            "      <td>...</td>\n",
                            "      <td>25.53</td>\n",
                            "      <td>152.50</td>\n",
                            "      <td>1709.0</td>\n",
                            "      <td>0.1444</td>\n",
                            "      <td>0.4245</td>\n",
                            "      <td>0.4504</td>\n",
                            "      <td>0.2430</td>\n",
                            "      <td>0.3613</td>\n",
                            "      <td>0.08758</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>84348301</td>\n",
                            "      <td>M</td>\n",
                            "      <td>11.42</td>\n",
                            "      <td>20.38</td>\n",
                            "      <td>77.58</td>\n",
                            "      <td>386.1</td>\n",
                            "      <td>0.14250</td>\n",
                            "      <td>0.28390</td>\n",
                            "      <td>0.2414</td>\n",
                            "      <td>0.10520</td>\n",
                            "      <td>...</td>\n",
                            "      <td>26.50</td>\n",
                            "      <td>98.87</td>\n",
                            "      <td>567.7</td>\n",
                            "      <td>0.2098</td>\n",
                            "      <td>0.8663</td>\n",
                            "      <td>0.6869</td>\n",
                            "      <td>0.2575</td>\n",
                            "      <td>0.6638</td>\n",
                            "      <td>0.17300</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>84358402</td>\n",
                            "      <td>M</td>\n",
                            "      <td>20.29</td>\n",
                            "      <td>14.34</td>\n",
                            "      <td>135.10</td>\n",
                            "      <td>1297.0</td>\n",
                            "      <td>0.10030</td>\n",
                            "      <td>0.13280</td>\n",
                            "      <td>0.1980</td>\n",
                            "      <td>0.10430</td>\n",
                            "      <td>...</td>\n",
                            "      <td>16.67</td>\n",
                            "      <td>152.20</td>\n",
                            "      <td>1575.0</td>\n",
                            "      <td>0.1374</td>\n",
                            "      <td>0.2050</td>\n",
                            "      <td>0.4000</td>\n",
                            "      <td>0.1625</td>\n",
                            "      <td>0.2364</td>\n",
                            "      <td>0.07678</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows  33 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 17
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "To model the data, we will need to remove useless columns like the 'id' and 'Unnamed: 32' column as well as map the 'M' and 'B' diagnoses to -1 and 1, respectively."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "# Clean data\n",
                "diagnosis_map = {'M': 1, 'B': - 1}\n",
                "original_data[\"diagnosis\"] = original_data[\"diagnosis\"].map(diagnosis_map)\n",
                "original_data.drop(original_data.columns[[-1, 0]], axis=1,  inplace=True)\n",
                "original_data.head()\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
                            "0          1        17.99         10.38          122.80     1001.0   \n",
                            "1          1        20.57         17.77          132.90     1326.0   \n",
                            "2          1        19.69         21.25          130.00     1203.0   \n",
                            "3          1        11.42         20.38           77.58      386.1   \n",
                            "4          1        20.29         14.34          135.10     1297.0   \n",
                            "\n",
                            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
                            "0          0.11840           0.27760          0.3001              0.14710   \n",
                            "1          0.08474           0.07864          0.0869              0.07017   \n",
                            "2          0.10960           0.15990          0.1974              0.12790   \n",
                            "3          0.14250           0.28390          0.2414              0.10520   \n",
                            "4          0.10030           0.13280          0.1980              0.10430   \n",
                            "\n",
                            "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
                            "0         0.2419  ...         25.38          17.33           184.60   \n",
                            "1         0.1812  ...         24.99          23.41           158.80   \n",
                            "2         0.2069  ...         23.57          25.53           152.50   \n",
                            "3         0.2597  ...         14.91          26.50            98.87   \n",
                            "4         0.1809  ...         22.54          16.67           152.20   \n",
                            "\n",
                            "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
                            "0      2019.0            0.1622             0.6656           0.7119   \n",
                            "1      1956.0            0.1238             0.1866           0.2416   \n",
                            "2      1709.0            0.1444             0.4245           0.4504   \n",
                            "3       567.7            0.2098             0.8663           0.6869   \n",
                            "4      1575.0            0.1374             0.2050           0.4000   \n",
                            "\n",
                            "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
                            "0                0.2654          0.4601                  0.11890  \n",
                            "1                0.1860          0.2750                  0.08902  \n",
                            "2                0.2430          0.3613                  0.08758  \n",
                            "3                0.2575          0.6638                  0.17300  \n",
                            "4                0.1625          0.2364                  0.07678  \n",
                            "\n",
                            "[5 rows x 31 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>diagnosis</th>\n",
                            "      <th>radius_mean</th>\n",
                            "      <th>texture_mean</th>\n",
                            "      <th>perimeter_mean</th>\n",
                            "      <th>area_mean</th>\n",
                            "      <th>smoothness_mean</th>\n",
                            "      <th>compactness_mean</th>\n",
                            "      <th>concavity_mean</th>\n",
                            "      <th>concave points_mean</th>\n",
                            "      <th>symmetry_mean</th>\n",
                            "      <th>...</th>\n",
                            "      <th>radius_worst</th>\n",
                            "      <th>texture_worst</th>\n",
                            "      <th>perimeter_worst</th>\n",
                            "      <th>area_worst</th>\n",
                            "      <th>smoothness_worst</th>\n",
                            "      <th>compactness_worst</th>\n",
                            "      <th>concavity_worst</th>\n",
                            "      <th>concave points_worst</th>\n",
                            "      <th>symmetry_worst</th>\n",
                            "      <th>fractal_dimension_worst</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>17.99</td>\n",
                            "      <td>10.38</td>\n",
                            "      <td>122.80</td>\n",
                            "      <td>1001.0</td>\n",
                            "      <td>0.11840</td>\n",
                            "      <td>0.27760</td>\n",
                            "      <td>0.3001</td>\n",
                            "      <td>0.14710</td>\n",
                            "      <td>0.2419</td>\n",
                            "      <td>...</td>\n",
                            "      <td>25.38</td>\n",
                            "      <td>17.33</td>\n",
                            "      <td>184.60</td>\n",
                            "      <td>2019.0</td>\n",
                            "      <td>0.1622</td>\n",
                            "      <td>0.6656</td>\n",
                            "      <td>0.7119</td>\n",
                            "      <td>0.2654</td>\n",
                            "      <td>0.4601</td>\n",
                            "      <td>0.11890</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>20.57</td>\n",
                            "      <td>17.77</td>\n",
                            "      <td>132.90</td>\n",
                            "      <td>1326.0</td>\n",
                            "      <td>0.08474</td>\n",
                            "      <td>0.07864</td>\n",
                            "      <td>0.0869</td>\n",
                            "      <td>0.07017</td>\n",
                            "      <td>0.1812</td>\n",
                            "      <td>...</td>\n",
                            "      <td>24.99</td>\n",
                            "      <td>23.41</td>\n",
                            "      <td>158.80</td>\n",
                            "      <td>1956.0</td>\n",
                            "      <td>0.1238</td>\n",
                            "      <td>0.1866</td>\n",
                            "      <td>0.2416</td>\n",
                            "      <td>0.1860</td>\n",
                            "      <td>0.2750</td>\n",
                            "      <td>0.08902</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1</td>\n",
                            "      <td>19.69</td>\n",
                            "      <td>21.25</td>\n",
                            "      <td>130.00</td>\n",
                            "      <td>1203.0</td>\n",
                            "      <td>0.10960</td>\n",
                            "      <td>0.15990</td>\n",
                            "      <td>0.1974</td>\n",
                            "      <td>0.12790</td>\n",
                            "      <td>0.2069</td>\n",
                            "      <td>...</td>\n",
                            "      <td>23.57</td>\n",
                            "      <td>25.53</td>\n",
                            "      <td>152.50</td>\n",
                            "      <td>1709.0</td>\n",
                            "      <td>0.1444</td>\n",
                            "      <td>0.4245</td>\n",
                            "      <td>0.4504</td>\n",
                            "      <td>0.2430</td>\n",
                            "      <td>0.3613</td>\n",
                            "      <td>0.08758</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1</td>\n",
                            "      <td>11.42</td>\n",
                            "      <td>20.38</td>\n",
                            "      <td>77.58</td>\n",
                            "      <td>386.1</td>\n",
                            "      <td>0.14250</td>\n",
                            "      <td>0.28390</td>\n",
                            "      <td>0.2414</td>\n",
                            "      <td>0.10520</td>\n",
                            "      <td>0.2597</td>\n",
                            "      <td>...</td>\n",
                            "      <td>14.91</td>\n",
                            "      <td>26.50</td>\n",
                            "      <td>98.87</td>\n",
                            "      <td>567.7</td>\n",
                            "      <td>0.2098</td>\n",
                            "      <td>0.8663</td>\n",
                            "      <td>0.6869</td>\n",
                            "      <td>0.2575</td>\n",
                            "      <td>0.6638</td>\n",
                            "      <td>0.17300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1</td>\n",
                            "      <td>20.29</td>\n",
                            "      <td>14.34</td>\n",
                            "      <td>135.10</td>\n",
                            "      <td>1297.0</td>\n",
                            "      <td>0.10030</td>\n",
                            "      <td>0.13280</td>\n",
                            "      <td>0.1980</td>\n",
                            "      <td>0.10430</td>\n",
                            "      <td>0.1809</td>\n",
                            "      <td>...</td>\n",
                            "      <td>22.54</td>\n",
                            "      <td>16.67</td>\n",
                            "      <td>152.20</td>\n",
                            "      <td>1575.0</td>\n",
                            "      <td>0.1374</td>\n",
                            "      <td>0.2050</td>\n",
                            "      <td>0.4000</td>\n",
                            "      <td>0.1625</td>\n",
                            "      <td>0.2364</td>\n",
                            "      <td>0.07678</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows  31 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The 'diagnosis' column is what we are trying to predict, so we pull out that column to be our target.  Then, we normalize the features of the dataset to make it easier for our model to train."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "# Split into features and targets and normalize\n",
                "Y = original_data.loc[:, \"diagnosis\"]\n",
                "X = original_data.iloc[:, 1:]\n",
                "\n",
                "X_normalized = (X - X.min())/(X.max() - X.min())\n",
                "X_norm_copy = X_normalized.copy()\n",
                "X_normalized.head()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
                            "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
                            "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
                            "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
                            "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
                            "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
                            "\n",
                            "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
                            "0          0.792037        0.703140             0.731113       0.686364   \n",
                            "1          0.181768        0.203608             0.348757       0.379798   \n",
                            "2          0.431017        0.462512             0.635686       0.509596   \n",
                            "3          0.811361        0.565604             0.522863       0.776263   \n",
                            "4          0.347893        0.463918             0.518390       0.378283   \n",
                            "\n",
                            "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
                            "0                0.605518  ...      0.620776       0.141525         0.668310   \n",
                            "1                0.141323  ...      0.606901       0.303571         0.539818   \n",
                            "2                0.211247  ...      0.556386       0.360075         0.508442   \n",
                            "3                1.000000  ...      0.248310       0.385928         0.241347   \n",
                            "4                0.186816  ...      0.519744       0.123934         0.506948   \n",
                            "\n",
                            "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
                            "0    0.450698          0.601136           0.619292         0.568610   \n",
                            "1    0.435214          0.347553           0.154563         0.192971   \n",
                            "2    0.374508          0.483590           0.385375         0.359744   \n",
                            "3    0.094008          0.915472           0.814012         0.548642   \n",
                            "4    0.341575          0.437364           0.172415         0.319489   \n",
                            "\n",
                            "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
                            "0              0.912027        0.598462                 0.418864  \n",
                            "1              0.639175        0.233590                 0.222878  \n",
                            "2              0.835052        0.403706                 0.213433  \n",
                            "3              0.884880        1.000000                 0.773711  \n",
                            "4              0.558419        0.157500                 0.142595  \n",
                            "\n",
                            "[5 rows x 30 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>radius_mean</th>\n",
                            "      <th>texture_mean</th>\n",
                            "      <th>perimeter_mean</th>\n",
                            "      <th>area_mean</th>\n",
                            "      <th>smoothness_mean</th>\n",
                            "      <th>compactness_mean</th>\n",
                            "      <th>concavity_mean</th>\n",
                            "      <th>concave points_mean</th>\n",
                            "      <th>symmetry_mean</th>\n",
                            "      <th>fractal_dimension_mean</th>\n",
                            "      <th>...</th>\n",
                            "      <th>radius_worst</th>\n",
                            "      <th>texture_worst</th>\n",
                            "      <th>perimeter_worst</th>\n",
                            "      <th>area_worst</th>\n",
                            "      <th>smoothness_worst</th>\n",
                            "      <th>compactness_worst</th>\n",
                            "      <th>concavity_worst</th>\n",
                            "      <th>concave points_worst</th>\n",
                            "      <th>symmetry_worst</th>\n",
                            "      <th>fractal_dimension_worst</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.521037</td>\n",
                            "      <td>0.022658</td>\n",
                            "      <td>0.545989</td>\n",
                            "      <td>0.363733</td>\n",
                            "      <td>0.593753</td>\n",
                            "      <td>0.792037</td>\n",
                            "      <td>0.703140</td>\n",
                            "      <td>0.731113</td>\n",
                            "      <td>0.686364</td>\n",
                            "      <td>0.605518</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.620776</td>\n",
                            "      <td>0.141525</td>\n",
                            "      <td>0.668310</td>\n",
                            "      <td>0.450698</td>\n",
                            "      <td>0.601136</td>\n",
                            "      <td>0.619292</td>\n",
                            "      <td>0.568610</td>\n",
                            "      <td>0.912027</td>\n",
                            "      <td>0.598462</td>\n",
                            "      <td>0.418864</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.643144</td>\n",
                            "      <td>0.272574</td>\n",
                            "      <td>0.615783</td>\n",
                            "      <td>0.501591</td>\n",
                            "      <td>0.289880</td>\n",
                            "      <td>0.181768</td>\n",
                            "      <td>0.203608</td>\n",
                            "      <td>0.348757</td>\n",
                            "      <td>0.379798</td>\n",
                            "      <td>0.141323</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.606901</td>\n",
                            "      <td>0.303571</td>\n",
                            "      <td>0.539818</td>\n",
                            "      <td>0.435214</td>\n",
                            "      <td>0.347553</td>\n",
                            "      <td>0.154563</td>\n",
                            "      <td>0.192971</td>\n",
                            "      <td>0.639175</td>\n",
                            "      <td>0.233590</td>\n",
                            "      <td>0.222878</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.601496</td>\n",
                            "      <td>0.390260</td>\n",
                            "      <td>0.595743</td>\n",
                            "      <td>0.449417</td>\n",
                            "      <td>0.514309</td>\n",
                            "      <td>0.431017</td>\n",
                            "      <td>0.462512</td>\n",
                            "      <td>0.635686</td>\n",
                            "      <td>0.509596</td>\n",
                            "      <td>0.211247</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.556386</td>\n",
                            "      <td>0.360075</td>\n",
                            "      <td>0.508442</td>\n",
                            "      <td>0.374508</td>\n",
                            "      <td>0.483590</td>\n",
                            "      <td>0.385375</td>\n",
                            "      <td>0.359744</td>\n",
                            "      <td>0.835052</td>\n",
                            "      <td>0.403706</td>\n",
                            "      <td>0.213433</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.210090</td>\n",
                            "      <td>0.360839</td>\n",
                            "      <td>0.233501</td>\n",
                            "      <td>0.102906</td>\n",
                            "      <td>0.811321</td>\n",
                            "      <td>0.811361</td>\n",
                            "      <td>0.565604</td>\n",
                            "      <td>0.522863</td>\n",
                            "      <td>0.776263</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.248310</td>\n",
                            "      <td>0.385928</td>\n",
                            "      <td>0.241347</td>\n",
                            "      <td>0.094008</td>\n",
                            "      <td>0.915472</td>\n",
                            "      <td>0.814012</td>\n",
                            "      <td>0.548642</td>\n",
                            "      <td>0.884880</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>0.773711</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0.629893</td>\n",
                            "      <td>0.156578</td>\n",
                            "      <td>0.630986</td>\n",
                            "      <td>0.489290</td>\n",
                            "      <td>0.430351</td>\n",
                            "      <td>0.347893</td>\n",
                            "      <td>0.463918</td>\n",
                            "      <td>0.518390</td>\n",
                            "      <td>0.378283</td>\n",
                            "      <td>0.186816</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.519744</td>\n",
                            "      <td>0.123934</td>\n",
                            "      <td>0.506948</td>\n",
                            "      <td>0.341575</td>\n",
                            "      <td>0.437364</td>\n",
                            "      <td>0.172415</td>\n",
                            "      <td>0.319489</td>\n",
                            "      <td>0.558419</td>\n",
                            "      <td>0.157500</td>\n",
                            "      <td>0.142595</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows  30 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 19
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## From Scratch Implementation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "With the data cleaned up, let's see how our from-scratch implementation does."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "# Train/test split\n",
                "X_normalized.insert(loc=len(X_norm_copy.columns),\n",
                "                    column=\"intercept\", value=1)  # add bias to features\n",
                "\n",
                "train_features, train_targets, test_features, test_targets = split_data.train_test_split(\n",
                "    X_norm_copy.values.T, Y.values.reshape((1, Y.shape[0])))\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "# Train model\n",
                "svm_model = svm.SVM(train_features.shape[0])\n",
                "svm_model.fit(train_features, train_targets)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "| epoch 1 | loss 5881.17683128923\n",
                        "| epoch 2 | loss 4989.1526879641515\n",
                        "| epoch 4 | loss 4202.566112544171\n",
                        "| epoch 8 | loss 3497.2428434958674\n",
                        "| epoch 16 | loss 2952.421453727741\n",
                        "| epoch 32 | loss 2403.7305643670525\n",
                        "| epoch 64 | loss 1946.8350998176736\n",
                        "| epoch 128 | loss 1632.992039014368\n",
                        "| epoch 256 | loss 1428.0734152416796\n",
                        "| epoch 512 | loss 1335.457984091465\n",
                        "| epoch 1024 | loss 1293.5906217425197\n",
                        "| epoch 2048 | loss 1265.193972956656\n",
                        "| epoch 4096 | loss 1274.2730194449553\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "# Test model\n",
                "predictions = svm_model.predict(test_features)\n",
                "print(\n",
                "    f\"Accuray = {np.sum(predictions == test_targets)/predictions.shape[1] * 100 :2.3f}%\")\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Accuray = 97.368%\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As we can see, the model is pretty accurate at around 97%!  Unfortuntaely, it took the model quite a while to go through four thousand epochs."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Sklearn Implementation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's now see how the Sklearn implementation stacks up."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "# Train-test split\n",
                "train_features, test_features, train_targets, test_targets = train_test_split(\n",
                "    X_normalized.values, Y)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "# Train model\n",
                "linear_svm = LinearSVC(loss=\"hinge\", max_iter=5000)\n",
                "linear_svm.fit(train_features, train_targets, )\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "LinearSVC(loss='hinge', max_iter=5000)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 24
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "# Test model\n",
                "predictions = linear_svm.predict(test_features)\n",
                "print(\n",
                "    f\"Accuray = {np.sum(predictions == test_targets)/predictions.shape[0] * 100 :2.3f}%\")\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Accuray = 97.902%\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The Sklearn implementation also reaches an accuracy of 97% but takes only a fraction of time when compared to the from-scratch implementation.  This ought to be an area for further investigation."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In this exhibition we showed a from-scratch implementation of a linear support vector machine that performs just as well as its industry-standard, Sklearn counterpart.  SVM's, when combined with kernel functions, are fast and accurate white-box classifiers are able to tackle many high-dimensional datasets.  If I wanted to extend this exhibition further, I would incorporate kernel functions so that nonlinear datasets (polar/circual datasets, for example) can still be separated.  "
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}